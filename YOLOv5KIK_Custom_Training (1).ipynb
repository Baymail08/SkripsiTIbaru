{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hrsaDfdVHzxt"},"source":["# Custom Data Training with YOLOv5\n","\n","Berikut Ini adalah Program Deteksi Pakaian Safety\n","\n","\n","\n","![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)"]},{"cell_type":"markdown","metadata":{"id":"yNveqeA1KXGy"},"source":["# Step 1: Install Requirements Serta Library Yang Dibutuhkan"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTvDNSILZoN9","outputId":"248423ae-052a-4f07-89e2-cb9d3dfe7c03","executionInfo":{"status":"ok","timestamp":1698673638892,"user_tz":-420,"elapsed":26705,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"source":["#clone YOLOv5 and\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","%pip install -qr requirements.txt # install dependencies\n","%pip install -q roboflow\n","\n","import torch\n","import os\n","from IPython.display import Image, clear_output  # to display images\n","\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 16031, done.\u001b[K\n","remote: Counting objects: 100% (64/64), done.\u001b[K\n","remote: Compressing objects: 100% (39/39), done.\u001b[K\n","remote: Total 16031 (delta 35), reused 40 (delta 25), pack-reused 15967\u001b[K\n","Receiving objects: 100% (16031/16031), 14.61 MiB | 19.48 MiB/s, done.\n","Resolving deltas: 100% (11001/11001), done.\n","/content/yolov5\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m644.8/644.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSetup complete. Using torch 2.1.0+cu118 (Tesla T4)\n"]}]},{"cell_type":"markdown","metadata":{"id":"zP6USLgz2f0r"},"source":["# Step 2: Memasukan Dataset\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"R2wGvjd4Z_92","outputId":"63833262-5073-4a66-f21a-33307e0b4767","executionInfo":{"status":"error","timestamp":1698673833612,"user_tz":-420,"elapsed":372,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"source":["#from roboflow import Roboflow\n","#rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"],"execution_count":5,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2f6135367ffe>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mroboflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"yolov5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ultralytics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/roboflow/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, model_format, notebook)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monboarding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/roboflow/__init__.py\u001b[0m in \u001b[0;36mauth\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"onboarding\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/roboflow/__init__.py\u001b[0m in \u001b[0;36mcheck_key\u001b[0;34m(api_key, model, notebook, num_retries)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m\"API Key is of Incorrect Type \\n Expected Type: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: API Key is of Incorrect Type \n Expected Type: <class 'str'>\n Input Type: <class 'NoneType'>"]}]},{"cell_type":"code","metadata":{"id":"FwJcaoPGF4VI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f349e350-6acf-43be-c71d-b6c79e3339cd","executionInfo":{"status":"ok","timestamp":1698673826644,"user_tz":-420,"elapsed":5921,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=\"g3Yzj4xjvOGN5it6nKG1\")\n","project = rf.workspace(\"deteksi-pakaian-safety\").project(\"pakaian-safety-uwyss\")\n","dataset = project.version(1).download(\"yolov5\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Pakaian-Safety-1 to yolov5pytorch:: 100%|ˆˆˆˆˆˆˆˆˆˆ| 3419/3419 [00:00<00:00, 66232.79it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Pakaian-Safety-1 in yolov5pytorch:: 100%|ˆˆˆˆˆˆˆˆˆˆ| 236/236 [00:00<00:00, 9105.47it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"X7yAi9hd-T4B"},"source":["# Step 3: Train Our Custom YOLOv5 model\n","\n","Here, we are able to pass a number of arguments:\n","- **img:** define input image size\n","- **batch:** determine batch size\n","- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n","- **data:** Our dataset locaiton is saved in the `dataset.location`\n","- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n","- **cache:** cache images for faster training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaFNnxLJbq4J","outputId":"fd4424fb-99c6-4636-a80b-35b93d690b61","executionInfo":{"status":"ok","timestamp":1698673936020,"user_tz":-420,"elapsed":90490,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"source":["!python train.py --img 416 --batch 16 --epochs 20 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-30 13:50:51.172372: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-30 13:50:51.172430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-30 13:50:51.172472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/Pakaian-Safety-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n","YOLOv5 =€ v7.0-231-gc2f131a Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 =€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 20.2MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 181MB/s]\n","\n","Overriding model.yaml nc=80 with nc=7\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [7, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7038508 parameters, 7038508 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/Pakaian-Safety-1/train/labels... 77 images, 0 backgrounds, 0 corrupt: 100% 77/77 [00:00<00:00, 616.73it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/Pakaian-Safety-1/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 77/77 [00:00<00:00, 286.41it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/Pakaian-Safety-1/valid/labels... 22 images, 0 backgrounds, 0 corrupt: 100% 22/22 [00:00<00:00, 441.00it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/Pakaian-Safety-1/valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 22/22 [00:00<00:00, 214.76it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.56 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/19      1.56G     0.1202    0.06863    0.06132        176        416: 100% 5/5 [00:09<00:00,  1.89s/it]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:03<00:00,  3.21s/it]\n","                   all         22        319     0.0033     0.0493    0.00201    0.00055\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/19      1.56G     0.1187    0.07467     0.0606        209        416: 100% 5/5 [00:00<00:00,  5.76it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.07it/s]\n","                   all         22        319    0.00333      0.051    0.00209   0.000498\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/19      1.56G      0.115    0.07684    0.05898        229        416: 100% 5/5 [00:00<00:00,  5.81it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.39it/s]\n","                   all         22        319    0.00341     0.0566    0.00212   0.000388\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/19      1.56G     0.1096    0.08336    0.05745        183        416: 100% 5/5 [00:00<00:00,  7.15it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.85it/s]\n","                   all         22        319    0.00594      0.112    0.00383    0.00076\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/19      1.56G     0.1075    0.08429    0.05626        176        416: 100% 5/5 [00:00<00:00,  6.79it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.92it/s]\n","                   all         22        319    0.00799       0.13    0.00567    0.00125\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/19      1.56G     0.1038    0.09658    0.05456        248        416: 100% 5/5 [00:00<00:00,  5.00it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.66it/s]\n","                   all         22        319     0.0102      0.183    0.00867    0.00199\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/19      1.56G     0.1005      0.105    0.05275        252        416: 100% 5/5 [00:01<00:00,  3.61it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.34it/s]\n","                   all         22        319     0.0129      0.234     0.0186    0.00437\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/19      1.56G    0.09698    0.09841    0.05033        144        416: 100% 5/5 [00:00<00:00,  6.67it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.74it/s]\n","                   all         22        319     0.0134      0.266     0.0256    0.00593\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/19      1.56G    0.09386    0.08629    0.04742        135        416: 100% 5/5 [00:00<00:00,  6.10it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.16it/s]\n","                   all         22        319      0.216      0.138     0.0389     0.0101\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/19      1.56G    0.09188    0.08817    0.04519        160        416: 100% 5/5 [00:00<00:00,  6.52it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.03s/it]\n","                   all         22        319      0.218      0.173     0.0412     0.0106\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/19      1.56G    0.08636    0.09213     0.0427        123        416: 100% 5/5 [00:00<00:00,  7.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.15s/it]\n","                   all         22        319      0.222      0.176     0.0466     0.0124\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/19      1.56G     0.0865     0.0883      0.042        170        416: 100% 5/5 [00:01<00:00,  4.72it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.51s/it]\n","                   all         22        319      0.404      0.204     0.0709     0.0188\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/19      1.56G    0.08669     0.0992    0.03969        182        416: 100% 5/5 [00:00<00:00,  5.74it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.04it/s]\n","                   all         22        319      0.205      0.242     0.0423      0.012\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/19      1.56G    0.08354    0.09333    0.03852        175        416: 100% 5/5 [00:00<00:00,  6.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.08it/s]\n","                   all         22        319      0.405      0.241     0.0901     0.0262\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/19      1.56G    0.08209    0.08648    0.03706        159        416: 100% 5/5 [00:00<00:00,  6.15it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.17it/s]\n","                   all         22        319      0.585       0.23     0.0954     0.0275\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/19      1.56G    0.07879    0.09462    0.03462        149        416: 100% 5/5 [00:00<00:00,  5.81it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.15it/s]\n","                   all         22        319      0.594      0.263      0.111     0.0328\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/19      1.56G    0.07765    0.09266    0.03468        207        416: 100% 5/5 [00:00<00:00,  6.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.08it/s]\n","                   all         22        319      0.431      0.247      0.116     0.0319\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/19      1.56G    0.07699    0.09339    0.03404        227        416: 100% 5/5 [00:01<00:00,  4.58it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.34s/it]\n","                   all         22        319      0.443       0.25      0.124     0.0359\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/19      1.56G    0.07558    0.09596    0.03389        222        416: 100% 5/5 [00:00<00:00,  6.32it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n","                   all         22        319      0.442      0.248       0.12     0.0361\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/19      1.56G    0.07578    0.09106    0.03399        249        416: 100% 5/5 [00:01<00:00,  4.68it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.28it/s]\n","                   all         22        319      0.448      0.257      0.134      0.041\n","\n","20 epochs completed in 0.015 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7029004 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.26it/s]\n","                   all         22        319      0.448      0.257      0.134     0.0413\n","                Celana         22         69      0.356       0.24      0.279     0.0962\n","                  Helm         22        105       0.17      0.543      0.257     0.0759\n","               Pakaian         22         82      0.163      0.756      0.265     0.0751\n","                Sepatu         22         46          0          0          0          0\n","                celana         22          8          1          0          0          0\n","               pakaian         22          9          1          0    0.00395   0.000395\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"jtmS7_TXFsT3"},"source":["#Run Inference  With Trained Weights\n","#(TESTING GAMBAR)\n","Menjalankan file dari folder `test/images` dari hasil download Roboflow."]},{"cell_type":"code","metadata":{"id":"TWjjiBcic3Vz","executionInfo":{"status":"aborted","timestamp":1698673639452,"user_tz":-420,"elapsed":14,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"source":["!python detect.py --weights runs/train/exp2/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZbUn4_b9GCKO","executionInfo":{"status":"aborted","timestamp":1698673639453,"user_tz":-420,"elapsed":15,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"source":["#Menampilkan semua hasil dari uji testing gambar\n","\n","import glob\n","from IPython.display import Image, display\n","\n","for imageName in glob.glob('/content/yolov5/yolov5/runs/detect/exp3/*.jpg'): #assuming JPG\n","    display(Image(filename=imageName))\n","    print(\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Uji testing video"],"metadata":{"id":"vzZBKQDMQACi"}},{"cell_type":"code","source":["!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 410 --conf 0.35 --source /content/VID_20220926_103406.mp4"],"metadata":{"id":"sIiFqSJRPyYg","executionInfo":{"status":"aborted","timestamp":1698673639453,"user_tz":-420,"elapsed":14,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qVGrcQMa1hZU","executionInfo":{"status":"aborted","timestamp":1698673639453,"user_tz":-420,"elapsed":14,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger = 'TensorBoard' #@param ['TensorBoard']\n","\n","if logger == 'TensorBoard':\n","  %load_ext tensorboard\n","  %tensorboard --logdir /content/yolov5/yolov5/runs/train"],"metadata":{"id":"iujk3uBqpH9p","executionInfo":{"status":"aborted","timestamp":1698673639454,"user_tz":-420,"elapsed":15,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HAALVhZFpHex","executionInfo":{"status":"aborted","timestamp":1698673639454,"user_tz":-420,"elapsed":15,"user":{"displayName":"Eri Zuliarso","userId":"14451678377504036399"}}},"execution_count":null,"outputs":[]}]}